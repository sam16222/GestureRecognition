<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>GestureAR by sam16222</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">GestureAR</h1>
      <h2 class="project-tagline">Robust hand gestural interaction for smartphone based applications</h2>
      <a href="https://github.com/sam16222/GestureRecognition/zipball/master/videos" class="btn">Dataset</a>
      <!--a href="https://github.com/sam16222/GestureRecognition/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/sam16222/GestureRecognition/tarball/master" class="btn">Download .tar.gz</a-->
    </section>

    <section class="main-content">
      <h3>
<a id="welcome-to-gestar" class="anchor" href="#welcome-to-gestar" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Welcome to GestAR</h3>

<p>The future of UI in AR and VR applications will be dominated by hand gestures. In this paper, we are exploring an intuitive hand-gesture based interaction for smartphones having a limited computational capability. To this end, we present an efficient algorithm for gesture recognition with First Person View (FPV) that focuses on recognizing a four swipe model (Left, Right, Up and Down) for smartphones through single monocular camera vision. This can be used with frugal AR/VR devices such as <a href="https://vr.google.com/cardboard/">Google Cardboard</a> and <a href="http://www.wearality.com/">Wearality</a> in building AR/VR based automation systems, for large scale deployments by providing a touch-less interface with real-time performance. We take into account multiple cues, including palm color, hand contour segmentation, and motion tracking which effectively deals with FPV constraints caused due to a wearable device. </p>

<h3>
<a id="the-idea" class="anchor" href="#the-idea" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Idea</h3>

<p><img src="https://github.com/sam16222/GestureRecognition/blob/master/img/Image-Flow-Diagram.png?raw=true?" alt="Algorithmic Flow Diagram "></p>

<p>We propose a technique for hand gesture classification by categorising the hand motion in four type of swipes such as Up, Down, Left and Right which can be used for triggering different types of events which are intuitive for wearable AR/VR gadgets. We circumvent the shortcomings of the probabilistic models for hand detection by using a simpler palm detection model that works purely on <strong>Cb</strong> and <strong>Cr</strong> values using a statistical model. The step generates multiple blobs on the palm segment. Contour detection filters the blobs that are small and hence would not correspond to palm. A Shi-Tomasi detector based simple approach is applied for feature point detection on the contour boundary. The motion of these feature points is analysed by computing the optical flow based displacement. The aggregate measure of the displacement is used for labelling the swipe under major groups. The approach is computationally simple and can be run on an ordinary smart-phone. We demonstrate the performance of this approach on more than hundred of sample video segments with over <em>95%</em> classification accuracy. This technique can be easily integrated with many applications for the overlaid information traversal spanning multiple pages. </p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/sam16222/GestureRecognition">GestureAR</a> is maintained by <a href="https://github.com/sam16222">sam16222</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
